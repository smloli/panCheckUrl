package main

import (
	"fmt"
	"log"
	"net/http"
	"strings"
	"os"
	"regexp"
	"encoding/json"
	"io/ioutil"
)

type Url struct{
	urlList []string // é“¾æ¥åˆ—è¡¨
	id map[string]bool // é“¾æ¥ID
	validUrl []string // æœ‰æ•ˆé“¾æ¥
	errUrl []string // æ— æ•ˆé“¾æ¥
	Pwd map[string]string	//æå–ç map
}

// é˜¿é‡Œè¿”å›çŠ¶æ€ç 
type RespCode struct{
    Code string
	Share_name string
}

// ä¸ºäº†è·å–é‡å®šå‘çš„locationï¼Œè¦é‡æ–°å®ç°ä¸€ä¸ªhttp.Client
var client = &http.Client{
	CheckRedirect: func(req *http.Request, via []*http.Request) error {
	return http.ErrUseLastResponse
	},
}

func aliYunCheck(_url *string) (start string, shareName string) {
	log.SetPrefix("aliYunCheck():")
    share_id := (*_url)[30:]
    var respcode RespCode
    url := "https://api.aliyundrive.com/adrive/v3/share_link/get_share_by_anonymous?share_id=" + share_id
    param := map[string]string{
        "share_id": share_id,
    }
    jsonParam, _ := json.Marshal(param)
    req, _ := http.NewRequest("POST", url, strings.NewReader(string(jsonParam)))
    req.Header.Set("User-Agent", "Mozilla/5.0 (Linux; Android 11; SM-G9880) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/95.0.4638.37 Mobile Safari/537.36")
    req.Header.Set("Referer", "https://www.aliyundrive.com/")
    resp, err := client.Do(req)
    if err != nil {
        log.Print(err)
		return
    }
    defer resp.Body.Close()
    body, _ := ioutil.ReadAll(resp.Body)
    json.Unmarshal(body, &respcode)
	if respcode.Code == "" {
		start = "âˆš"
		shareName = respcode.Share_name
	} else {
		start = "Ã—"
	}
    return
}

func baiduYunCheck(_url *string) (start string) {
	log.SetPrefix("baiduYunCheck():")
	// è®¿é—®ç½‘ç›˜é“¾æ¥
	req, _ := http.NewRequest("GET", *_url, nil)
	// UAå¿…é¡»æ˜¯æ‰‹æœºçš„ï¼Œå¦åˆ™ç½‘é¡µä¸ä¼šé‡å®šå‘
	req.Header.Set("User-Agent", "Mozilla/5.0 (iPhone; CPU iPhone OS 13_2_3 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/13.0.3 Mobile/15E148 Safari/604.1 Edg/94.0.4606.81")
	resp, err := client.Do(req)
	if err != nil {
		log.Print(err)
		return
	}
	defer resp.Body.Close()
	// è·å–é‡å®šå‘åœ°å€
	location, err := resp.Location()
	if err != nil {
		log.Print(err)
		return
	}
	locationUrl := location.String()
	// æ£€æµ‹é“¾æ¥æ˜¯å¦å¤±æ•ˆ
	index := strings.Index(locationUrl, "error")
	if index != -1 {
		start = "Ã—"
	} else {
		start = "âˆš"
	}
	return
}

// æ£€æµ‹é“¾æ¥æœ‰æ•ˆæ€§
func (url *Url) checkUrl(flag bool) {
	// æœ‰æ•ˆåˆ—è¡¨
	url.validUrl = make([]string, 1)
	url.id = make(map[string]bool)
	url.errUrl = make([]string, 1)
	var start string
	var shareName string
	var repeatUrl int //é‡å¤é“¾æ¥è®¡æ•°
	count := 1	//é“¾æ¥è®¡æ•°
	ferror, err := os.OpenFile("error.log", os.O_APPEND|os.O_WRONLY|os.O_CREATE, 0644)
	if err != nil {
		fmt.Println(err)
		return
	}
	log.SetPrefix("checkUrl():")
	log.SetOutput(ferror)
	defer func() {
		err := recover()
		if err != nil {
			log.Print(err)
		}
		ferror.Close()
	}()
	for _, _url := range (*url).urlList {
		// å»é‡
		if !url.id[_url] {
			url.id[_url] = true
		} else {
			fmt.Printf("å‘ç°é‡å¤é“¾æ¥ï¼Œå·²è·³è¿‡ï¼  %s \n", _url)
			repeatUrl++
			continue
		}
		index := strings.Index(_url, "baidu")
		if index != -1 {
			start = baiduYunCheck(&_url)	// ç™¾åº¦ç½‘ç›˜æ£€æµ‹
			if start == "" {
				continue
			}
			_url += " " + url.Pwd[_url]
			fmt.Printf("%d  %s  %s\n", count, _url, start)
		} else {
			start, shareName = aliYunCheck(&_url)	// é˜¿é‡Œäº‘ç›˜æ£€æµ‹
			// è¾“å‡ºé˜¿é‡Œäº‘ç›˜åˆ†äº«é“¾æ¥çš„æ–‡ä»¶å
			if start == "âˆš" {
				// æœ‰æå–ç çš„åŠ å…¥æå–ç ï¼Œæ²¡æœ‰çš„é»˜è®¤ä¸ºç©º
				_url = shareName + " " + _url + " " + url.Pwd[_url]
			} else if start == "" {
				continue
			}
			fmt.Printf("%d  %s  %s\n", count, _url, start)
		}
		count++
		// flag == true å°±è®°å½•
		if flag {
			if start == "âˆš" {
				if url.validUrl[0] == "" {
					url.validUrl[0] = _url
					continue
				}
				url.validUrl = append(url.validUrl, []string{_url}...)
			} else if start == "Ã—"{
				if url.errUrl[0] == "" {
					url.errUrl[0] = _url
					continue
				}
				url.errUrl = append(url.errUrl, []string{_url}...)
			}
		}
	}
	// å½“flagä¸ºtrueæ—¶ï¼Œå°†oklisté‡Œçš„å†…å®¹å†™å…¥åˆ°loli.txt
	// å¤±æ•ˆé“¾æ¥å†™å…¥å¤±æ•ˆé“¾æ¥.txt
	if flag {
		floli, err := os.Create("loli.txt")
		if err != nil {
			fmt.Println(err)
			return
		}
		for _, v := range url.validUrl {
			_, err := floli.WriteString(v + "\n")
			if err != nil {
				fmt.Println(err)
			}
		}
		floli.Close()
		ferrUrl, err := os.Create("å¤±æ•ˆé“¾æ¥.txt")
		if err != nil {
			fmt.Println(err)
			return
		}
		for _, v := range url.errUrl {
			_, err := ferrUrl.WriteString(v + "\n")
			if err != nil {
				fmt.Println(err)
			}
		}
		ferrUrl.Close()
	}
	fmt.Println("--------------------æ£€æµ‹ç»“æœ--------------------")
	fmt.Printf("æœ‰æ•ˆé“¾æ¥ï¼š%d/%d\n", len(url.validUrl), len(url.urlList))
	fmt.Printf("å¤±æ•ˆé“¾æ¥ï¼š%d/%d\n", len(url.errUrl), len(url.urlList))
	if repeatUrl != 0 {
		fmt.Printf("é‡å¤é“¾æ¥ï¼š%d/%d\n", repeatUrl, len(url.urlList))
	}
}

// è¯»å–url.txtæ–‡ä»¶é‡Œçš„é“¾æ¥
func (url *Url) getUrlList() {
	f, err := os.Open("url.txt")
	if err != nil {
		log.Fatal(err)
	}
	defer f.Close()
    fi, _ := f.Stat()
    if err != nil {
        log.Fatal("url.txtæ–‡ä»¶ä¸å­˜åœ¨")
    }
    data := make([]byte, fi.Size())
    _, err = f.Read(data)
    if err != nil {
        log.Fatal(err)
    }
    url.regexpUrl(&data)
}

// æ­£åˆ™åŒ¹é…url
func (url *Url) regexpUrl(data *[]byte) {
	url.Pwd = make(map[string]string)
	// æ— æå–ç è§„åˆ™
	re := regexp.MustCompile("(http[s]?://[www pan]+.[a-z]+.com/s/[0-9a-zA-Z_-]+)")
	// æå–ç è§„åˆ™1
	rePwd1 := regexp.MustCompile(`(æå–ç : [0-9a-zA-Z]{4})\s?\né“¾æ¥ï¼š(http[s]?://[www pan]+.[a-z]+.com/s/[0-9a-zA-Z_-]+)`)
	// æå–ç è§„åˆ™2	ç™¾åº¦ã€é˜¿é‡Œäº‘éƒ½é€‚ç”¨
	rePwd2 := regexp.MustCompile(`(http[s]?://[www pan]+.[a-z]+.com/s/[0-9a-zA-Z_-]+)\s(æå–ç :[\s]?[0-9a-zA-Z]{4})`)
	res := re.FindAllSubmatch(*data, -1)
	resPwd1 := rePwd1.FindAllSubmatch(*data, -1)
	resPwd2 := rePwd2.FindAllSubmatch(*data, -1)
    // å°†åŒ¹é…åˆ°çš„urlå†™å…¥åˆ°url.urlList
    for _, v := range res {
		_url := strings.TrimSpace(string(v[1]))
        if url.urlList[0] == "" {
			url.urlList[0] = _url
			continue
		}
		url.urlList = append(url.urlList, []string{_url}...)
	}
	// å°†æœ‰æå–ç çš„é“¾æ¥å†™åˆ°mapé‡Œ
	for _, v := range resPwd1 {
		_url := strings.TrimSpace(string(v[2]))
		url.Pwd[_url] = string(v[1])
	}
	for _, v := range resPwd2 {
		_url := strings.TrimSpace(string(v[1]))
		url.Pwd[_url] = string(v[2])
	}
}

func main() {
	var url Url
	var num string
	var loli string
	var tmp string
	var flag bool  // æ£€æµ‹æ¨¡å¼
	url.urlList = make([]string, 1)
	fmt.Println("-------------ç™¾åº¦ã€é˜¿é‡Œäº‘ç›˜é“¾æ¥æœ‰æ•ˆæ€§æ£€æµ‹-------------")
	fmt.Println()
	fmt.Println("-----------------æ”¯æŒçš„é“¾æ¥æ ¼å¼-----------------")
	fmt.Println("https://pan.baidu.com/s/1lXSQI-33cEXB8GMXNAFlrQ")
	fmt.Println("é“¾æ¥:https://pan.baidu.com/s/1U88Wwm560vbvyJX0cw9J-Q æå–ç :7deh")
	fmt.Println("é“¾æ¥: http://pan.baidu.com/s/1c0Er78G å¯†ç : 2cci")
	fmt.Println("é“¾æ¥: https://pan.baidu.com/s/1YZnL2-TC3Wy5bshU7fntxg æå–ç : qku6 å¤åˆ¶è¿™æ®µå†…å®¹åæ‰“å¼€ç™¾åº¦ç½‘ç›˜æ‰‹æœºAppï¼Œæ“ä½œæ›´æ–¹ä¾¿å“¦")
	fmt.Println("https://www.aliyundrive.com/s/6riFVSGytcv")
	fmt.Println("æˆ‘ç”¨é˜¿é‡Œäº‘ç›˜åˆ†äº«äº†ã€Œloli.7z.pngã€ï¼Œä½ å¯ä»¥ä¸é™é€Ÿä¸‹è½½ğŸš€ å¤åˆ¶è¿™æ®µå†…å®¹æ‰“å¼€ã€Œé˜¿é‡Œäº‘ç›˜ã€App å³å¯è·å– é“¾æ¥ï¼šhttps://www.aliyundrive.com/s/bEBTKwaCK4K")
	fmt.Println("------------------------------------------------")
	fmt.Print("0.å•ä¸ªæ£€æµ‹\n1.æ‰¹é‡æ£€æµ‹ï¼ˆè¯»å–è½¯ä»¶è¿è¡Œç›®å½•url.txtæ–‡ä»¶é‡Œçš„æ¯ä¸€è¡Œé“¾æ¥ï¼Œæ£€æµ‹å®Œè‡ªåŠ¨å°†æœ‰æ•ˆé“¾æ¥å¯¼å‡ºè‡³loli.txtï¼‰\n")
	fmt.Println("------------------------------------------------")
	fmt.Print("num:")
	fmt.Scanln(&num)
	switch num {
		case "0":
			fmt.Print("url:")
			// å¤„ç†å­—ç¬¦ä¸²é‡Œçš„ç©ºæ ¼,ç„¶åæ‹¼æ¥
			for {
				n, _ := fmt.Scanf("%s", &tmp)
				if n == 0 {
					break
				}
				loli += tmp + " "
			}
            urlData := []byte(loli)
            url.regexpUrl(&urlData)
		case "1":
			flag = true
			url.getUrlList()
	}
	url.checkUrl(flag)
}
